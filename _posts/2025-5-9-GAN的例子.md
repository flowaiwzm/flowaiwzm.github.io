``````python
from __future__ import print_function
import random
import torch.nn as nn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
 
# 设置随机算子
manualSeed = 999
random.seed(manualSeed)
torch.manual_seed(manualSeed)
 
# 数据集位置
dataroot = "data/celeba"
 
# dataloader的核数
workers = 2
 
# Batch大小
batch_size = 128
 
# 图像缩放大小
image_size = 64
 
# 图像通道数
nc = 3
 
# 隐向量维度
nz = 100
 
# 生成器特征维度
ngf = 64
 
# 判别器特征维度
ndf = 64
 
# 训练轮数
num_epochs = 5
 
# 学习率
lr = 0.0002
 
# Adam优化器的beta系数
beta1 = 0.5
 
# gpu个数
ngpu = 1
 
# 加载数据集
dataset = dset.ImageFolder(root=dataroot,
                           transform=transforms.Compose([
                               transforms.Resize(image_size),
                               transforms.CenterCrop(image_size),
                               transforms.ToTensor(),
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                           ]))
# 创建dataloader
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                         shuffle=True, num_workers=workers)
 
# 使用cpu还是gpu
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")
 
# 初始化权重
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)
 
# 生成器
class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )
 
    def forward(self, input):
        return self.main(input)
 
# 实例化生成器并初始化权重
netG = Generator(ngpu).to(device)
netG.apply(weights_init)
 
# 判别器
class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )
 
    def forward(self, input):
        return self.main(input)
 
# 实例化判别器并初始化权重
netD = Discriminator(ngpu).to(device)
netD.apply(weights_init)
 
 
# 损失函数
criterion = nn.BCELoss()
 
# 随机输入噪声
fixed_noise = torch.randn(64, nz, 1, 1, device=device)
 
# 真实标签与虚假标签
real_label = 1.
fake_label = 0.
 
# 创建优化器
optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))
 
# 开始训练
img_list = []
G_losses = []
D_losses = []
iters = 0
 
print("Starting Training Loop...")
for epoch in range(num_epochs):
    for i, data in enumerate(dataloader, 0):
        ############################
        # (1) 更新D: 最大化 log(D(x)) + log(1 - D(G(z)))
        ###########################
        # 使用真实标签的batch训练
        netD.zero_grad()
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)
        output = netD(real_cpu).view(-1)
        errD_real = criterion(output, label)
        errD_real.backward()
        D_x = output.mean().item()
 
        # 使用虚假标签的batch训练
        noise = torch.randn(b_size, nz, 1, 1, device=device)
        fake = netG(noise)
        label.fill_(fake_label)
        output = netD(fake.detach()).view(-1)
        errD_fake = criterion(output, label)
        errD_fake.backward()
        D_G_z1 = output.mean().item()
        errD = errD_real + errD_fake
        # 更新D
        optimizerD.step()
 
        ############################
        # (2) 更新G: 最大化 log(D(G(z)))
        ###########################
        netG.zero_grad()
        label.fill_(real_label)
        output = netD(fake).view(-1)
        errG = criterion(output, label)
        errG.backward()
        D_G_z2 = output.mean().item()
        # 更新G
        optimizerG.step()
 
        # 输出训练状态
        if i % 50 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, num_epochs, i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))
 
        # 保存每轮loss
        G_losses.append(errG.item())
        D_losses.append(errD.item())
 
        # 记录生成的结果
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))
 
        iters += 1
 
# loss曲线
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()
 
 
# 生成效果图
real_batch = next(iter(dataloader))
 
# 真实图像
plt.figure(figsize=(15,15))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))
 
# 生成的虚假图像
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list[-1],(1,2,0)))
plt.show()
``````

---

您的代码实现了一个标准的 **DCGAN（Deep Convolutional GAN）**，包含生成器（`NetG`）和判别器（`NetD`），结构清晰且符合DCGAN的设计原则。以下是代码的逐层分析和关键设计点总结：

---

### **1. 生成器（NetG）分析**
#### **输入输出**
- **输入**：噪声向量（维度 `noise_dim`，默认为100），形状为 `(batch_size, noise_dim, 1, 1)`。
- **输出**：生成的RGB图像（96×96×3），值域通过 `Tanh()` 归一化到 `[-1, 1]`。

#### **反卷积层（ConvTranspose2d）结构**
| 层序 | 操作                       | 输入尺寸  | 输出尺寸    | 说明                                                       |
| ---- | -------------------------- | --------- | ----------- | ---------------------------------------------------------- |
| 1    | `ConvTranspose2d(100→512)` | 1×1×100   | 4×4×512     | 将噪声展开为4×4特征图，通道数为 `feature_dim*8`（默认512） |
| 2    | `ConvTranspose2d(512→256)` | 4×4×512   | 8×8×256     | 步长2，填充1，尺寸加倍                                     |
| 3    | `ConvTranspose2d(256→128)` | 8×8×256   | 16×16×128   | 同上                                                       |
| 4    | `ConvTranspose2d(128→64)`  | 16×16×128 | 32×32×64    | 同上                                                       |
| 5    | `ConvTranspose2d(64→3)`    | 32×32×64  | **96×96×3** | 通过核大小5、步长3、填充1，直接上采样到96×96，输出RGB图像  |

#### **关键设计**
- **批归一化（BatchNorm）**：每层反卷积后（除输出层）添加 `BatchNorm2d`，稳定训练。
- **激活函数**：使用 `ReLU`（最后一层用 `Tanh`），符合DCGAN标准。
- **权重初始化**：反卷积层权重从 `N(0.01, 0.02)` 初始化，避免梯度爆炸。

---

### **2. 判别器（NetD）分析**
#### **输入输出**
- **输入**：96×96×3的RGB图像（真实或生成）。
- **输出**：标量概率（通过 `Sigmoid`），表示输入图像为真实的置信度。

#### **卷积层（Conv2d）结构**
| 层序 | 操作              | 输入尺寸  | 输出尺寸  | 说明                                               |
| ---- | ----------------- | --------- | --------- | -------------------------------------------------- |
| 1    | `Conv2d(3→64)`    | 96×96×3   | 32×32×64  | 核5、步长3，快速降维（非标准DCGAN设计，通常步长2） |
| 2    | `Conv2d(64→128)`  | 32×32×64  | 16×16×128 | 步长2，标准下采样                                  |
| 3    | `Conv2d(128→256)` | 16×16×128 | 8×8×256   | 同上                                               |
| 4    | `Conv2d(256→512)` | 8×8×256   | 4×4×512   | 同上                                               |
| 5    | `Conv2d(512→1)`   | 4×4×512   | 1×1×1     | 输出单个值，通过 `Sigmoid` 映射为概率              |

#### **关键设计**
- **激活函数**：使用 `LeakyReLU(0.2)`（避免梯度消失），与生成器对称。
- **批归一化**：除输入层外均添加 `BatchNorm2d`。
- **权重初始化**：卷积层权重从 `N(0.0, 0.02)` 初始化。

---

### **3. 潜在问题与改进建议**
#### **问题1：生成器最后一层的反卷积参数**
- **当前**：`ConvTranspose2d(64→3, kernel=5, stride=3, padding=1)` 将32×32→96×96，可能因步长和核大小不匹配导致边缘伪影。
- **建议**：改用更常见的 `kernel=4, stride=2, padding=1` 逐步上采样到64×64→128×128（需调整生成器结构）。

#### **问题2：判别器第一层的步长3卷积**
- **当前**：`Conv2d(3→64, kernel=5, stride=3)` 将96×96→32×32，可能丢失过多信息。
- **建议**：改为 `stride=2`，或使用多个步长2卷积逐步下采样。

#### **其他改进**
1. **添加Dropout**：在判别器的全连接层（如果有）或中间层添加Dropout，防止过拟合。
2. **梯度惩罚**：考虑使用WGAN-GP的梯度惩罚替代 `Sigmoid`，提升训练稳定性。

---

### **4. 完整结构总结**
| 网络     | 层类型          | 输入尺寸→输出尺寸    | 激活函数       |
| -------- | --------------- | -------------------- | -------------- |
| **NetG** | ConvTranspose2d | 1×1×100 → 4×4×512    | ReLU           |
|          | ConvTranspose2d | 4×4×512 → 8×8×256    | ReLU           |
|          | ConvTranspose2d | 8×8×256 → 16×16×128  | ReLU           |
|          | ConvTranspose2d | 16×16×128 → 32×32×64 | ReLU           |
|          | ConvTranspose2d | 32×32×64 → 96×96×3   | Tanh           |
| **NetD** | Conv2d          | 96×96×3 → 32×32×64   | LeakyReLU(0.2) |
|          | Conv2d          | 32×32×64 → 16×16×128 | LeakyReLU(0.2) |
|          | Conv2d          | 16×16×128 → 8×8×256  | LeakyReLU(0.2) |
|          | Conv2d          | 8×8×256 → 4×4×512    | LeakyReLU(0.2) |
|          | Conv2d          | 4×4×512 → 1×1×1      | Sigmoid        |

---

### **5. 使用示例（生成图像）**
```python
# 初始化生成器
config = Config()
gen = NetG(config).to(config.device)

# 生成随机噪声
noise = torch.randn(1, config.noise_dim, 1, 1).to(config.device)

# 生成图像
fake_image = gen(noise)  # 输出尺寸: (1, 3, 96, 96)

# 可视化
import matplotlib.pyplot as plt
plt.imshow(fake_image.squeeze().permute(1, 2, 0).cpu().detach().numpy() * 0.5 + 0.5)
plt.show()
```

您的实现完全符合DCGAN的核心思想，只需注意个别层的参数选择是否适合目标分辨率，其余部分可直接用于训练！