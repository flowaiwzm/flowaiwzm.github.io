#### 机器学习基础

---

- $Accuracy=\frac{correct}{total}$其中$correct$为正确分类样本的个数。$total$为总样本分类个数，当模型鉴于关注的是坏样本时，或者正负样本非常不平衡时，应该合理选择评判指标。$R=\frac{TP}{TP+FN}$;

- **解析解**就是给出解的具体函数形式，从解的表达式中就可以算出任何对应值；**数值解**就是用数值方法求出近似解，给出一系列对应的自变量和解

- 求解的时候加上**单位矩阵**其实就是对线性回归引入**正则化**的过程

- **L1正则化**（也叫Lasso回归）是在目标函数中加上与系数的**绝对值相关的项**，而**L2正则化**（也叫岭回归）则是在目标函数中加上与**系数的平方相关的项**。L2正则化会使**参数的绝对值变小**，增强模型的稳定性（不会因为数据变化而产生很大的震荡）；而L1正则化会使一些参数为零,可以实现**特征稀疏**, 增强模型解释性。

- **生成式模型**先对数据的联合分布进行建模，然后再通过贝叶斯公式计算样本属于各类别的后验概率 。

  **判别式模型**直接进行**条件概率**建模，由数据直接学习决策函数或条件概率分布作为预测的模型。判别方法**不关心背后的数据分布**，关心的是对于给定的输入，应该预测什么样的输出。

  **由生成模型可以得到判别模型，但由判别模型得不到生成模型。**

|                | 优点                                                         | 缺点                                                         |                           代表算法                           |
| -------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **生成式模型** | 由于**统计了数据的分布情况**，所以其实际带的信息要比判别模型丰富，对于研究单类问题来说也比判别模型灵活性强； 模型可以通过增量学习得到（增量学习是指一个学习系统能不断地从新样本中学习新的知识，并能保存大部分以前已经学习到的知识）； 收敛速度更快，当样本容量增加的时，生成模型可以更快的收敛于真实模型； 隐变量存在时，也可以使用。 | 学习和计算过程比较复杂，由于学习了更多的样本信息，所以计算量大，如果我们只是做分类，就浪费了这部分的计算量； 准确率较差； 往往需要对特征进行假设，比如朴素贝叶斯中需要假设特征间独立同分布，所以如果所选特征不满足这个条件，将极大影响生成式模型的性能。 |    朴素贝叶斯、贝叶斯网络、隐马尔可夫模型、隐马尔可夫模型    |
| **判别式模型** | 由于关注的是数据的边界，所以能清晰的分辨出多类或某一类与其他类之间的差异，所以准确率相对较高； 计算量较小，需要的样本数量也较小； | 不能反映训练数据本身的特性； 收敛速度较慢                    | k 近邻法、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、条件随机场 |

---

#### 机器学习简介（4-26）

**机器学习ML**为人工智能的一个子领域，它涉及学习算法来处理各种预测问题和任务；

- 机器学习算法的主要类型

  - Supervised learning 监督式学习
  - Unsupervised learning 无监督学习
  - Recommender systems 推荐系统
  - Reinforcement learning 强化学习

- **监督式学习（Supervised learning）**

  在监督式学习中，将训练给定**输入X**的算法来**预测输出Y**，算法通过给它正确的答案来学习。

  - 经典实例---**使用回归来解决房价预测**

		``````
		一个数据集其中包含房屋价格和房屋大小，现在给定一个新房屋大小的情况下来预测房屋的价格；通过训练模型来预测改价格，回归模型通过数据集点拟合一条线，并将其作为预测因子，通过数据拟合不同的线条从而提供不同的模型行为和预测；---这学习算法称为回归
		``````

![image-20250426150345488](C:\Users\lwj\AppData\Roaming\Typora\typora-user-images\image-20250426150345488.png)

- **监督学习的另一类分类问题**---相比于回归，区别在于尝试预测较少数量的输出和类别。

  - 经典实例---**乳腺癌检测分类模型**

  - ``````
    训练一个来区分肿瘤是良性还是恶性的分类模型，在分类中，可以采用两个和多个输入。例如使用年龄和肿瘤大小。学习算法通过数据拟合边界线来有利于输出最终 诊断
    ``````
    
  - ![image-20250426151401979](C:\Users\lwj\AppData\Roaming\Typora\typora-user-images\image-20250426151401979.png)
  
- **无监督学习（Unsupervised Learning）**

  - 继监督学习后，使用最广泛的机器学习形式就是**无监督学习**。在处理无监督学习是，处理的数据与任何output labels y无关。例如有年龄和肿瘤的数据，但是**没有任何指标**表明肿瘤是良性还是恶性。

  - 无监督学习的任务基本上是在数据中找到一些结构和有用的东西，而无需预先添加这些标签，算法将能够检测可以表示两个不同组的两组数据点。---**聚类分析**---将相似的数据点分组在一起

  - ``````
    新闻按照主题对每日新闻进行聚类
    对遗传或DNA数据进行聚类
    客户资料分类
    ``````

  - 无监督学习---数据仅带有inputs $x$,但不带有任何output labels $y$。然后设计算法，**目标是在提供的数据中查找结构**；

  - **聚类**---将相似的数据点分组在一起；**异常检测**---查找异常数据点，例如金融交易中的异常事件；**降维PCA主成分分析**---目的在于使用更少的维度压缩数据，而不会丢死太多信息。


---

#### **回归模型Regression Model**

- **线性回归模型**
  - 特征和目标变量的训练集
  - $f(x)=wx+b$线性回归中的单个特征$x$时，它称为单变量线性回归
  - Cost Function Formula 损失函数公式
  - KL散度两个概率分布之间的距离的度量
- **VAE**
- **RNN循环神经网络----时间序列 **
- **GAN**

  - ``````python
    noise_shape=100
    def generator_model():
        
        
    ``````

  - 
