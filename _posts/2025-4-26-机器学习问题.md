#### 机器学习基础

---

- $Accuracy=\frac{correct}{total}$其中$correct$为正确分类样本的个数。$total$为总样本分类个数，当模型鉴于关注的是坏样本时，或者正负样本非常不平衡时，应该合理选择评判指标。$R=\frac{TP}{TP+FN}$;

- **解析解**就是给出解的具体函数形式，从解的表达式中就可以算出任何对应值；**数值解**就是用数值方法求出近似解，给出一系列对应的自变量和解

- 求解的时候加上**单位矩阵**其实就是对线性回归引入**正则化**的过程

- **L1正则化**（也叫Lasso回归）是在目标函数中加上与系数的**绝对值相关的项**，而**L2正则化**（也叫岭回归）则是在目标函数中加上与**系数的平方相关的项**。L2正则化会使**参数的绝对值变小**，增强模型的稳定性（不会因为数据变化而产生很大的震荡）；而L1正则化会使一些参数为零,可以实现**特征稀疏**, 增强模型解释性。

- **生成式模型**先对数据的联合分布进行建模，然后再通过贝叶斯公式计算样本属于各类别的后验概率 。

  **判别式模型**直接进行**条件概率**建模，由数据直接学习决策函数或条件概率分布作为预测的模型。判别方法**不关心背后的数据分布**，关心的是对于给定的输入，应该预测什么样的输出。

  **由生成模型可以得到判别模型，但由判别模型得不到生成模型。**

|                | 优点                                                         | 缺点                                                         |                           代表算法                           |
| -------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **生成式模型** | 由于**统计了数据的分布情况**，所以其实际带的信息要比判别模型丰富，对于研究单类问题来说也比判别模型灵活性强； 模型可以通过增量学习得到（增量学习是指一个学习系统能不断地从新样本中学习新的知识，并能保存大部分以前已经学习到的知识）； 收敛速度更快，当样本容量增加的时，生成模型可以更快的收敛于真实模型； 隐变量存在时，也可以使用。 | 学习和计算过程比较复杂，由于学习了更多的样本信息，所以计算量大，如果我们只是做分类，就浪费了这部分的计算量； 准确率较差； 往往需要对特征进行假设，比如朴素贝叶斯中需要假设特征间独立同分布，所以如果所选特征不满足这个条件，将极大影响生成式模型的性能。 |    朴素贝叶斯、贝叶斯网络、隐马尔可夫模型、隐马尔可夫模型    |
| **判别式模型** | 由于关注的是数据的边界，所以能清晰的分辨出多类或某一类与其他类之间的差异，所以准确率相对较高； 计算量较小，需要的样本数量也较小； | 不能反映训练数据本身的特性； 收敛速度较慢                    | k 近邻法、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、条件随机场 |

