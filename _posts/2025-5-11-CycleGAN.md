#### CycleGAN原理

单一的GAN模型无法实现风格迁移任务，因为GAN是通过生成器和判别器不断动态对抗优化，使得生成器学习到真实数据的特征分布。**而风格迁移的目的**使源域和目的域之间产生映射关系，即生成的图片在内容上与内容数据集的结构相似度高，风格上与风格数据集的结构相似度高。单一 的GAN模型出现的映射组合的**不确定性**；

**CycleGAN**利用对偶的训练方式来实现源域到目标域之间**无需具有成对关系**也能产生映射。使得CycleGAN具有不需要成对的数据集便可实现迁移功能的特征；由此循环对抗模型使得模型变成两个生成器*G*和*F*，两个判别器网络$D_x$和$D_y$,又增加了**循环一致性的损失函数**（L2范数损失函数--最小平方误差）来约束生成图片和真实图片的结构相似度；

![img](https://i-blog.csdnimg.cn/blog_migrate/43f67621561950eb94d6ff86db2aa34c.png)

**CycleGAN的不足**

- **生成器G**中虽然CycleGAN使用**auto-encoder框架**，进行下采样和上采样，在中间也使用了**残差网络**，想要更深层提取特征的同时防止网络退化。但其只能在局部进行**单尺度提取特征**，这限制了整体网络的学习能力。且**上采样单纯使用反卷积ConvTranspose2d**，图片生成质量将会受到影响。
- **判别器*D***--*CycleGAN*采用的是马尔科夫链*PatchGAN*的判别器结构。由于是基于卷积块结构，对于高频的模拟只能视野局限在局部窗口中。因此会大大降低学习效率
- **目标函数**--原始GAN的交叉熵损失函数中使用到的***JS散度***很难拉近生成数据的分布和真实数据的分布，***LSGAN***的最小二乘法通过将图片的分布尽可能拉到接近**决策边界**来缓解GAN训练模型的不稳定性和生成质量多样性不足的问题，但实际上问题依旧存在
-  对于**循环一致性损失**部分，CycleGAN使用的是L2范数损失函数，其目的是想让生成图片与真实图片的结构相似度更高。而L2范数损失是逐像素比较相似度的，忽略了图像本身的结构。因此简单的L2范数损失函数很难完成所有的风格迁移工作。且有时候L2范数的结果会与人的感知审美出现违背情况。
- python test.py --dataroot datasets/fire/testA --name fire_pretrained --model test --no_dropout