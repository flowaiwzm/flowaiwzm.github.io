#### Neural Networks from Scratch in python

- **Neuron Code（神经元）**

  - ``````python
    import sys
    import numpy as np
    import matplotlib
    
    input=[1,2,3]#输入
    weights1=[4,5,6]#权重1
    weights2=[4.5,5.6,8]#权重2
    weights3=[4.4,5.9,6]#权重3
    
    bias=3#偏差1
    bias=4#偏差2
    bias=6#偏差3
    #对layer进行编码
    #output列表list
    output=[inputs[0]*weights1[0]+inputs[1]*weights1[1]+inputs[2]*weights1[2]+bias1,
           inputs[0]*weights2[0]+inputs[1]*weights2[1]+inputs[2]*weights2[2]+bias2,
           inputs[0]*weights3[0]+inputs[1]*weights3[1]+inputs[2]*weights3[2]+bias3]
    print(output)
    #dot product点积/矩阵积 output=np.dot(weights,inputs)+bias
    #simplified code
    weights=[[4,5,6],[4.5,5.6,8],[4.4,5.9,6]]
    biases=[3,4,6]
    output=np.dot(weights,inputs)+biases
    #np.dot(weights,inputs)=[np.dot(weights[0],inputs),np.dot(weights[1],inputs),np.dot(weights[3],inputs)]
    print(output)
    #张量是数组的对象
    #批处理、层和对象 Batches,Layer,Object
    #np.array().T数组转置
    input=[[1,2,3],[1.2,2.2,3.2],[1.3,2.3,3.3]#输入
    weights=[[4,5,6],[4.5,5.6,8],[4.4,5.9,6]]
    biases=[3,4,6]
    biases2=[3,4,6]
    layer1_output=np.dot(weights,inputs)+biases
    layer2_output=np.dot(layer1_out,weight2)+biases2
     
           
    layer_outputs=[]
    for neuron_weights,neuron_bias in zip
    ``````
    
  - ``````python
    import numpy as np
    np.random.seed(0)
    x=[[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4]]
    
    class Layer_Dense:
    	def __init__(self,n_inputs,n_neurons):
    		self.weights=0.1*np.random.randn(n_inputs,n_nerons)
    		self.biases=np.zeros(1,n_nerons)
    	def forward(self,inputs):
            self.output=np.dot(input,self.weights)+self.biases
    class Activation_ReLU：
    	def forward(self,inputs):
            self.output=np.maxnum(0,inputs)
    layer1=Layer_Dense(4,5)
    layer2=Layer_Dense(5,2)
    
    layer1.forword(x)
    layer2.forword(layer.output)
    
    ``````
    
  - **隐藏层激活函数**
  
  - ``````python
    import numpy as np
    import matplotlib
    
    ``````
  
  - 