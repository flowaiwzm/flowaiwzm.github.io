# DETR: End-to-End Object Detection with Transformers (Paper Explained)

  

 主干网络+编码解码器（Transform(全局信息联系)）+预测头

- 想通过主干网络**CNN**提取图像特征，在送入**Transformer Encoder-Decoder**中主要在输入和输出部分进行修改；最后得到类别和bbox的预测并通过**二分匹配**计算损失来优化网络

**DETR的最大特点：无需预定义的先验anchor，也无需NMS的后处理策略，就可实现端到端的目标检测**

**Transformer的基本结构**

- 对于输入，首先进行**embedding操作**，将输入特征映射成向量的形式；两部分包含**input embedding**(将输入序列中token映射为连续的向量表示)和**positional encoding(**位置编码--一组与输入经过embedding操作后的向量相同维度的向量，用于提供位置信息。**input embedding**与**positional encoding**相加得到Transformer编码器的**输入**)
- **Transformer encoder**：是由多个编码模块组成的编码器层，每个编码模块由**多头自注意力机制+残差add+层归一化LayerNorm+前馈网络FFN+残差add+层归一化LayerNorm**组成
- **多头自注意力机制**：核心部分，例如，在CV领域，经过embedding层后的输入为[N, HW, C]，N为Batch num，HW为像素个数，**每个像素映射为一个维度为C的向量**；然后通过QKV的自注意力机制和划分为多头的方式，得到输出为[N, HW, C]：
- **要除以$\sqrt{d_k} $ 的原因**：查询（Query）与键（Key）之间的点积，然后将这个点积除以一个缩放因子，最后应用softmax函数来获得注意力权重。如果不进行缩放，当键的维度dk很大时，点积的结果可能会非常大，这会导致softmax函数的梯度非常小，从而引起梯度消失问题。通过除以根号$d_k$，提高训练的稳定性
- **Transformer decoder**:由多个解码模块组成的解码器层，每个解码模块由Masked**多头自注意力+残差add&层归一化LayerNorm+多头cross attention机制+add&&LayerNorm+前馈网络FFN+add&LayerNorm**
- 第一个解码模块的输入为output（可以初始化为0或者随机初始化）经过embedding操作后的结果，之后各个解码模块的输入就变为前一个编码模块的输出；第二个cross attention机制的QKV的输入分别为：KV键值对都是等于编码器的最终的输出而Q为Masked多头自注意力的输出
  - Masked多头自注意力机制：一个通俗解释为：一个词序列中，每个词只能被它前面的词所影响，所以这个词后面的所有位置都需要被忽略，所以在计算Attention的时候，该词向量和它后面的词向量的相关性为0。因此为Mask
- ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/60d734d6bbae84bd74bbb65488a73fce.png#pic_center)
- **DETR中的Encoder-Decoder中与transformer的区分**
- ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/7a0d83b0292df9825d819c1ab3f3f995.png#pic_center)
  - **spatial positional encoding**：新提出的二维空间位置编码方法，该位置编码分别被加入到了encoder的self attention的QK和decoder的cross attention的K，同时object queries也被加入到了decoder的两个attention（第一个加到了QK中，第二个加入了Q）中。而原版的Transformer将位置编码加到了input和output embedding中。-
  - DETR在计算attention的时候**没有使用masked attention**，因为将特征图展开成一维以后，所有像素都可能是互相关联的，因此没必要规定mask。-
  - **object queries的转换过程**：object queries是预定义的**目标查询的个数**，代码中默认为100。它的意义是：根据Encoder编码的特征，Decoder将100个查询转化成100个目标，即最终预测这100个目标的类别和bbox位置。**最终预测得到的shape应该为[N, 100, C]**，N为Batch Num，100个目标，C为预测的100个目标的类别数+1（背景类）以及bbox位置（4个值）。-
  - 得到预测结果以后，将**object predictions**和**ground truth box**之间通过**匈牙利算法**进行**二分匹配**：假如有K个目标，那么100个object predictions中就会有K个能够匹配到这K个ground truth，其他的都会和“no object”匹配成功，使其在理论上每个object query都有**唯一匹配**的目标，不会存在重叠，所以**DETR不需要nms进行后处理**。-
  - 分类loss采用的是**交叉熵损失**，针对所有predictions；bbox loss采用了***L1 loss***和***giou loss***，针对匹配成功的predictions 
- **匈牙利算法**用于解决二分图匹配的问题，即将Ground Truth的K个bbox和预测出的100个bbox作为二分图的两个集合，匈牙利算法的目标就是**找到最大匹配**，即在二分图中**最多能找到多少条没有公共端点的边**；**匈牙利算法的输入就是每条边的cost矩阵**![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/2c581a0620f40459551755e32600ba32.png#pic_center)

``````
Backbone 输出的特征图经过 1 × 1 卷积后进行降维，得到的是 d × H × W，被 reshape 成 d × H W 作为 Transformer Block 的输入。在 Encoder 阶段，会计算 H W × H W的 Attention Matrix，那么其实 Attention Matrix 上每一个值，其实就是考虑了 Backbone 输出的特征图空间上的两个点，因为 token 数量和特征图空间像素个数一样，那么这两个点，其实就已经构建出来了一个 box（左上角和右下角）。从这个角度来看，神经网络在基于 Attention Matrix 进行思考时，其实也可以从某种意义上就是在对一个个 bounding box 进行思考，这对于目标检测任务似乎是非常利好的。
``````

- **Backbone中的位置编码**
  - 正弦编码
  - 可学习编码

- 损失一般分为分类损失（交叉熵损失）和位置损失（L1损失）IOU损失