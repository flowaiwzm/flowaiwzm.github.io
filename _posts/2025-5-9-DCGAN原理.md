#### DCGAN网络（CNN_GAN）

**改进点：**

- 生成器*G*和判别器*D*舍弃传统CNN的池化层，判别器*D*保留CNN的整体框架而生成器*G*将卷积层替换成反卷积层（*ConvTranspose2d*）----目的 **D舍弃池化层的目的保留空间信息避免丢失局部信息，提升模型稳定性G使用反卷积层的目的实现可学习的上采样、避免棋盘伪影**
- 在判别器和生成器都采用用**批归一化BN层**来处理初始化不良导致的训练问题，加速模型训练，保证训练稳定性；
- 在生成器*G*中除了输出层使用**Tanh()**激活函数，其余层全部使用**ReLu**激活函数。而在判别器*G*中，出输出层外所有层都使用**LeakyReLu**激活函数**防止梯度稀疏。**

![img](https://i-blog.csdnimg.cn/blog_migrate/3b219040b8ee1f562e548c0b4e4efa3c.png)

``````python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader
# 数据准备
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(0.5, 0.5)
])
train_ds = torchvision.datasets.MNIST('data', train=True, transform=transform, download=True)
train_dl = DataLoader(train_ds, batch_size=4, shuffle=True)
# 生成器的初始化部分
# PS：1.输出层要用Tanh激活函数  2.使用batchnorm，解决初始化差的问题，帮助梯度传播到每一层，防止生成器包所有的样本都收敛到同一个点
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.linear1 = nn.Linear(100, 256 * 7 * 7)
        self.bn1 = nn.BatchNorm1d(256 * 7 * 7)
        # 这里是反卷积，stride=2即让图像放大2倍,padding=2即往里缩小两格。
        self.decon1 = nn.ConvTranspose2d(in_channels=256, out_channels=128,
                                         kernel_size=(3, 3),
                                         stride=1,
                                         padding=1)  # (128, 7, 7)
        self.bn2 = nn.BatchNorm2d(128)
        self.decon2 = nn.ConvTranspose2d(128, 64,
                                         kernel_size=(4, 4),
                                         stride=2,
                                         padding=1)  # (64, 14, 14)
        self.bn3 = nn.BatchNorm2d(64)
        self.decon3 = nn.ConvTranspose2d(64, 1,
                                         kernel_size=(4, 4),
                                         stride=2,
                                         padding=1)  # (1, 28, 28)
 
    def forward(self, x):
        x = F.relu(self.linear1(x))
        x = self.bn1(x)
        x = x.view(-1, 256, 7, 7)
        x = F.relu(self.decon1(x))
        x = self.bn2(x)
        x = F.relu(self.decon2(x))
        x = self.bn3(x)
        x = torch.tanh(self.decon3(x))
        return x
    
# 判别器的初始化部分
# PS：1.输入层不能用BN  2.用LeakyReLU激活函数  3.为了防止判别器过强而一边倒，用dropout降低其学习效果
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=2)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2)
        self.bn = nn.BatchNorm2d(128)
        self.fc = nn.Linear(128 * 6 * 6, 1)
 
    def forward(self, x):
        x = F.dropout2d(F.leaky_relu_(self.conv1(x)))  # nn.LeakyReLU() 更适合作为模型的一部分使用，因为它会返回一个新的张量，而不会修改原始数据
        x = F.dropout2d(F.leaky_relu_(self.conv2(x)))
        x = self.bn(x)
        x = x.view(-1, 128 * 6 * 6)
        x = self.fc(x)
        return x
    
# 初始化模型，定义优化器，损失函数
device = 'cuda' if torch.cuda.is_available() else 'cpu'
gen = Generator().to(device)
dis = Discriminator().to(device)
g_optim = optim.Adam(gen.parameters(), lr=1e-4)
d_optim = optim.Adam(dis.parameters(), lr=1e-5)  # PS：将判别器的学习率设置小一点可以减小其学习速度，防止一边倒
loss_fun = torch.nn.MSELoss()
# 定义绘图函数
test_input = torch.randn(16, 100, device=device)
 
 
def gen_img_plot(model, test_input):
    prediction = np.squeeze(model(test_input).detach().cpu().numpy())
    plt.figure(figsize=(4, 4))
    for i in range(16):
        plt.subplot(4, 4, i + 1)
        plt.imshow((prediction[i] + 1) / 2, cmap="gray")
        plt.axis("off")
    plt.show()
# 训练GAN
G_loss = []
D_loss = []
for epoch in range(20):
    g_epoch_loss = 0
    d_epoch_loss = 0
    count = len(train_dl)
    for step, (img, _) in enumerate(train_dl):
        img = img.to(device)
        size = img.size(0)
        random_noise = torch.randn(size, 100, device=device)
        # 优化判别器
        d_optim.zero_grad()
        # 优化真实图片
        real_output = dis(img)
        real_loss = loss_fun(real_output, torch.ones_like(real_output, device=device))
        real_loss.backward()
        # 优化生成图片
        gen_img = gen(random_noise)
        fake_output = dis(gen_img.detach())
        fake_loss = loss_fun(fake_output, torch.zeros_like(fake_output, device=device))
        fake_loss.backward()
 
        d_loss = real_loss + fake_loss
        d_optim.step()
 
        # 优化生成器
        g_optim.zero_grad()
        fake_output = dis(gen_img)
        g_loss = loss_fun(fake_output, torch.ones_like(fake_output, device=device))
        g_loss.backward()
        g_optim.step()
 
        with torch.no_grad():
            d_epoch_loss += d_loss.item()
            g_epoch_loss += g_loss.item()
 
    with torch.no_grad():
        d_epoch_loss /= count
        g_epoch_loss /= count
        D_loss.append(d_epoch_loss)
        G_loss.append(g_epoch_loss)
        print("Epoch:", epoch)
        gen_img_plot(gen, test_input)
 
plt.plot(D_loss, label="D_loss")
plt.plot(G_loss, label="G_loss")
plt.legend()
plt.show()
``````

