#### 常见数据处理方式

---

**1、视频等距抽帧成图片**

``````python
# 将视频导出为若干帧图片
DATA_DIR = "./#6) IR Video 6.MP4"  # 视频存放路径
SAVE_DIR = "./Images/IRphoto"  # 帧图片保存路径
GAP = 30  # 每隔多少帧导出一张图片

import cv2  # OpenCV库
import os

def getphoto(video_in, video_save):
    os.makedirs((video_save),exist_ok=True)
    number = 0
    cap = cv2.VideoCapture(video_in)  # 打开视频文件
    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 视频的帧数
    fps = cap.get(cv2.CAP_PROP_FPS)  # 视频的帧率
    dur = n_frames / fps  # 视频的时间
    num_frame = 0
    judge = cap.isOpened()
    while judge:
        flag, frame = cap.read()  # flag是读取状态，frame下一帧
        if cv2.waitKey(0) == 27:
            break
        if flag:
            num_frame += 1
            if num_frame % GAP == 0:
                print("正在保存第%d张照片" % number)
                cv2.imwrite(video_save + '/' + str(number) + '.jpg', frame)  # cv2.imwrite(‘路径’ + ‘名字’ + ‘后缀’， 要存的帧)
                number += 1
        else:
            break

    print("视频时长: %d 秒" % dur)
    print("视频共有帧数: %d 保存帧数为: %d" % (n_frames, number))
    print("每秒的帧数(FPS): %.1lf" % fps)


def main_1(path):
    video_in = path
    video_save = SAVE_DIR
    getphoto(video_in, video_save)

if __name__ == '__main__':
    paht = DATA_DIR  # 视频路径
    main_1(paht)

``````

---

**2、快速批量将数据集中选取的指定图片移动到新文件夹中**

``````python
#每隔30帧提取一张图片
import os
import shutil

## 新建目标文件夹
IsExists = os.path.exists('Images\Image_New_INF')    ##在目录中新建一个文件夹
if not IsExists:
    os.makedirs("Images\Image_New_INF")
else:
    print("目录已存在")
new_img_folder = "Images\Image_New_INF"

## 遍历读取文件夹筛选符合标准的图片
dir_path = "Images/INF2022530"       ## 将原始的数据集文件路径加载进来
for root,dirs,files in os.walk(dir_path):
    for file in files:
        num_name = file.rstrip(".jpg")   ## 将图片名末尾的.jpg去掉
        num_name_int = int(num_name)
        if num_name_int % 30 == 0:
            shutil.copy(os.path.join(root, file), new_img_folder)


``````

---

**3、快速批量修改文件夹中图片的后缀**

``````bat
利用txt中的ren *.jpg*.png保存后修改后缀.bat 即可得到.png格式的图片
``````

---

**4、将高分辨率图像分割成大小均匀图像**

**优势**

- **内存管理**：高分辨率图像通常占用大量内存。通过将它们分割成较小的图像，可以更有效地利用内存，使训练过程更加高效。
- **并行化**：小图像可以在多个处理器或GPU上并行处理，这可以大大提高训练速度
- **避免过拟合**：通过从大图像中提取出许多小图像，可以增加训练样本的数量，这有助于提高模型的泛化能力，避免过拟合。
- **学习局部特征**：在许多情况下，图像的局部特征（如纹理、形状等）对于任务来说可能是非常重要的。使用小图像可以使模型更专注于这些局部特征。
- **灵活性**：分割后的小图像可以适应各种网络结构，特别是那些设计用于处理固定大小输入的网络

``````python
import multiprocessing
import os
import sys
import cv2
import numpy as np
from tqdm import tqdm


def main():
    args = {
        "inputs_dir": "F:\Code\Python\SRGAN\SRGAN-PyTorch\data\SRGAN_ImageNet",  # 输入图像路径
        "output_dir": "data/SRGAN_ImageNet_train_GT_sub2",  # 输出图像路径
        "crop_size": 128,  # 图像尺寸
        "step": 64,  # 滑动步长
        "thresh_size": 0,  # Threshold size. If the remaining image is less than the threshold, it will not be cropped.
        "num_workers": 10  # 线程数
    }
    split_images(args)

def split_images(args: dict):
    """Split the image into multiple small images.

    Args:
        args (dict): Custom parameter dictionary.

    """

    inputs_dir = args["inputs_dir"]
    output_dir = args["output_dir"]
    num_workers = args["num_workers"]

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Create {output_dir} successful.")
    else:
        print(f"{output_dir} already exists.")
        sys.exit(1)

    # Get all image paths
    image_file_paths = os.listdir(inputs_dir)

    # Splitting images with multiple threads
    progress_bar = tqdm(total=len(image_file_paths), unit="image", desc="Split image")
    workers_pool = multiprocessing.Pool(num_workers)
    for image_file_path in image_file_paths:
        workers_pool.apply_async(worker, args=(image_file_path, args), callback=lambda arg: progress_bar.update(1))
    workers_pool.close()
    workers_pool.join()
    progress_bar.close()
    print("Split image successful.")


def worker(image_file_path: str, args: dict):
    """Split the image into multiple small images.

    Args:
        image_file_path (str): Image file path.
        args (dict): Custom parameter dictionary.

    """

    inputs_dir = args["inputs_dir"]
    output_dir = args["output_dir"]
    crop_size = args["crop_size"]
    step = args["step"]
    thresh_size = args["thresh_size"]

    image_name, extension = os.path.splitext(os.path.basename(image_file_path))
    image = cv2.imread(os.path.join(inputs_dir, image_file_path), cv2.IMREAD_UNCHANGED)

    image_height, image_width = image.shape[0:2]
    image_height_space = np.arange(0, image_height - crop_size + 1, step)
    if image_height - (image_height_space[-1] + crop_size) > thresh_size:
        image_height_space = np.append(image_height_space, image_height - crop_size)
    image_width_space = np.arange(0, image_width - crop_size + 1, step)
    if image_width - (image_width_space[-1] + crop_size) > thresh_size:
        image_width_space = np.append(image_width_space, image_width - crop_size)

    index = 0
    for h in image_height_space:
        for w in image_width_space:
            index += 1
            # Crop
            crop_image = image[h: h + crop_size, w:w + crop_size, ...]
            crop_image = np.ascontiguousarray(crop_image)
            # Save image
            cv2.imwrite(os.path.join(output_dir, f"{image_name}_{index:04d}{extension}"), crop_image)


if __name__ == "__main__":
    main()
``````

---

**5、批量修改原图片名称**

``````python
import os
import shutil
import re

class BatchRename():
    '''
    批量重命名文件夹中的图片文件

    '''
    def __init__(self):
        self.path = 'TestImages/INF/INF_resize_frame_480360/X4/002'  #表示需要命名处理的文件夹
        self.save_path='TestImages/INF/INF_resize_frame_480360/X4_name/002'#保存重命名后的图片地址
    def rename(self):
        filelist = os.listdir(self.path) #获取文件路径
        # filelist.sort(key=lambda x: int(x.split('.')[0])) # 先按照名称顺序排好序
        filelist.sort(key=lambda x: int(re.search(r'_(\d+)\.bmp$', x).group(1)))
        total_num = len(filelist) #获取文件长度（个数）
        i = 0 #表示文件的命名是从1开始的
        for item in filelist:
            print(item)
            if item.endswith(('.png','.jpg','.jpeg','.bmp')):  #初始的图片的格式为jpg格式的（或者源文件是png格式及其他格式，后面的转换格式就可以调整为自己需要的格式即可）
                src = os.path.join(os.path.abspath(self.path), item)#当前文件中图片的地址
                # dst = os.path.join(os.path.abspath(self.save_path), ''+'week'+str(i) + '.jpg')#处理后文件的地址和名称,可以自己按照自己的要求改进
                dst = os.path.join(os.path.abspath(self.save_path), f'{str(i).zfill(8)}.png')    # 使用了 str(i).zfill(8) 来确保数字部分总是有 8 位，不足的部分用前导零填充。
                image_name = f'{str(i).zfill(8)}.png'
                print(image_name)
                try:
                    # os.rename(src, dst)
                    shutil.copy(src, dst)
                    print ('converting %s to %s ...' % (src, dst))
                    i = i + 1
                except:
                    continue
        print ('total %d to rename & converted %d jpgs' % (total_num, i))

if __name__ == '__main__':
    demo = BatchRename()
    demo.rename()

``````

---

**6、使用OpenCV批量随机添加运动模糊、高斯噪声和泊松噪声**

``````python
import os
import cv2
import numpy as np
import random

src_folder = 'Images/Visible_Images'
dst_folder = 'Images/Visible_Images_addBlurNoise'

# 如果目标文件不存在，则创建它
# os.makedirs(dst_folder,exist_ok = True)

# 添加高斯噪声
def add_gaussian_noise(image,mean=0,stddev=25):
    noise = np.random.normal(mean,stddev,image.shape).astype(np.uint8)
    noise_image = cv2.add(image,noise)
    return noise_image

# 添加泊松噪声
def add_poisson_noise(image,scale=1.0):
    # noise = np.random.poisson(image/255.0*100).astype(np.uint8)
    vals = len(np.unique(image))
    vals = 2 ** np.ceil(np.log2(vals))
    noise = np.random.poisson(image / 255.0 * vals * scale) / float(vals) * 255
    # noise_image = cv2.add(image,noise)
    noise_image = noise.astype(np.uint8)
    return noise_image

# 遍历源文件中的所有文件
for filename in os.listdir(src_folder):
    # 构建完整的文件路径
    src_path = os.path.join(src_folder,filename)

    # 检查文件是否为图片
    # if filename.endswith((".png",".jpg",".jpeg",".bmp",".tiff")):
    if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
        img = cv2.imread(src_path,-1)

        # 检测图片是否读取成功
        if img is not None:
            # 应用高斯模糊，卷积核大小为（3,3）
            blurred_img = cv2.GaussianBlur(img,(3,3),0)

            # 随机决定石头添加高斯噪声或泊松噪声
            if random.choice(['gaussian','poission']) == 'gaussian':
                # 调整高斯噪声的标准差，增大stddev会增加噪声强度
                noise_img = add_gaussian_noise(blurred_img,mean=0, stddev=10)
            else:
                # 调整泊松噪声的scale因子，增大scale会增加噪声强度
                noise_img = add_poisson_noise(blurred_img,scale=1)

            output_name = filename[:-4]+"_GaussianBlurPoissonNoise"+".bmp"
            print(output_name)

            # 构建文件路径
            dst_path = os.path.join(dst_folder,output_name)

            # 保存图像
            cv2.imwrite(dst_path,noise_img)
        else:
            print(f"无法读取图像：{src_path}")
    else:
        print(f"跳过非图像文件：{src_path}")
print("所有图像已经成功添加高斯模糊和随机噪声并保存到指定路径：",dst_folder)

``````

---

**7、超分辨率重建--二阶降解模拟真实低分辨率图像**

[二阶降解模拟](https://blog.csdn.net/qq_40280673/article/details/140666858#t1)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e9747d11d3964a4aaa95367acc2b09bb.png#pic_center)

通过模拟真实世界中的图像降解过程来生成更逼真的低分辨率训练数据

---

**8、数据集图片尺寸调整**

``````python
import os
import cv2
from concurrent.futures import ThreadPoolExecutor

def process_image(filename, input_dir, output_dir, target_size):
    """处理单张图片"""
    try:
        input_path = os.path.join(input_dir, filename)
        output_path = os.path.join(output_dir, filename)

        img = cv2.imread(input_path)
        if img is None:
            print(f"警告：无法读取文件 {filename}，跳过")
            return

        resized_img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)
        cv2.imwrite(output_path, resized_img)
        print(f"已处理: {filename}")
    except Exception as e:
        print(f"处理 {filename} 时出错: {str(e)}")

def resize_images_parallel(input_dir, output_dir, target_size=(640, 512), max_workers=4):
    """多线程批量处理图片"""
    # 确保输出目录存在
    os.makedirs(output_dir, exist_ok=True)
    
    # 获取所有图片文件
    image_files = [f for f in os.listdir(input_dir) 
                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]

    # 使用线程池处理
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        for filename in image_files:
            executor.submit(
                process_image,
                filename, input_dir, output_dir, target_size
            )

    print("所有图片处理完成！")

if __name__ == "__main__":
    input_folder = "./Images/RGBphoto"  # 原始图片文件夹
    output_folder = "./Images/RGB-IRphoto"  # 输出文件夹
    target_size = (640, 512)  # 目标尺寸（宽度, 高度）
    
    # 调用并行处理函数
    resize_images_parallel(input_folder, output_folder, target_size)

``````

python train.py --dataroot ./datasets/fire --name fire_cyclegan --model cycle_gan --display_id 0

