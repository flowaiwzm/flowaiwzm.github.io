下面针对代码中根据 `self.upsampler` 不同分支所采用的“重建/上采样”方式，逐一进行说明和对比。主要包含以下四种情形：

1. **pixelshuffle（经典 SR 方案）**
2. **pixelshuffledirect（轻量化 SR 方案）**
3. **nearest+conv（真实场景 SR 方案）**
4. **else 分支下的纯卷积重建（针对去噪或去压缩伪影）**

------

## 1. pixelshuffle（经典 SR 方案）

```python
if self.upsampler == 'pixelshuffle':
    # for classical SR
    self.conv_before_upsample = nn.Sequential(
        nn.Conv2d(embed_dim, num_feat, 3, 1, 1),
        nn.LeakyReLU(inplace=True)
    )
    self.upsample = Upsample(upscale, num_feat)
    self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)
```

### 核心思路

- **子像素卷积（Sub-pixel Convolution）+ PixelShuffle**
   经典的超分辨率（SR）网络里，很常用“先用一个卷积把通道数扩张到 `scale^2 * C_out`，再调用 PyTorch 的 `PixelShuffle` 操作”来实现上采样（称为“子像素重排”）。这里假设 `Upsample` 模块内部就是先做一次常规卷积把通道扩到 `num_feat * (scale^2)`，然后 `nn.PixelShuffle(scale)` 将特征图的空间尺寸放大 `scale` 倍。
- **代码拆解**
  1. `conv_before_upsample = Conv(embed_dim → num_feat) + LeakyReLU`
     - 作用：从 backbone 或 Transformer 编码器输出的 `embed_dim` 维特征，先做一次常规 3×3 卷积，得到 `num_feat` 通道的特征图，并加激活。
     - 理由：通常先对特征进行一次 Bottleneck 或维度映射，使得后面的子像素卷积操作输入通道统一为 `num_feat`。
  2. `upsample = Upsample(upscale, num_feat)`
     - 作用：`Upsample` 模块内部大概率包含：
       - 再做一次卷积，把通道数从 `num_feat` 变到 `num_feat * (upscale^2)`。
       - 再调用 `nn.PixelShuffle(upscale)`，把 `(B, num_feat * scale^2, H, W)` → `(B, num_feat, H*scale, W*scale)`。
     - 效果：一次性将特征图放大 `scale` 倍，并保持通道数为 `num_feat`。
  3. `conv_last = Conv(num_feat → num_out_ch)`
     - 作用：上采样后的高分辨率特征再经一个 3×3 卷积映射到 `num_out_ch` 通道（例如 RGB → 3 通道），得到最终的重建/超分图像。

### 优点与适用场景

- **优点**
  - 相比插值（如双线性、最近邻），PixelShuffle 能够在一次卷积后直接“内部重排”得到高分辨率特征，减少了插值带来的模糊。
  - 经典的子像素方法在不少 SR 网络（如 ESPCN、EDSR、RCAN）里都取得了很好的效果。
- **缺点/局限**
  - 如果输入特征分辨率较大，或者 `scale` 很高（>4），则中间特征通道数要膨胀为 `num_feat * scale^2`，会带来参数量和显存开销。
  - 在真实场景（带噪声、低质量压缩图像等）下，单纯的子像素卷积有时会出现网格状伪影（checkerboard artifact）。

------

## 2. pixelshuffledirect（轻量化 SR 方案）

```python
elif self.upsampler == 'pixelshuffledirect':
    # for lightweight SR (to save parameters)
    self.upsample = UpsampleOneStep(
        upscale, 
        embed_dim, 
        num_out_ch, 
        (patches_resolution[0], patches_resolution[1])
    )
```

### 核心思路

- **一阶段“子像素”+ 直出输出**
   `pixelshuffledirect` 分支直接用了一个 `UpsampleOneStep` 模块，它的设计思路通常是：

  1. 不再把“卷积 → 中间 `num_feat` 通道 → 再卷积 → 扩张通道到 `num_feat * scale^2`”切分成两步，而是合并成一个“从 `embed_dim` 直接卷积到 `C_out * scale^2`”的子像素单层卷积。
  2. 然后一步 `PixelShuffle(scale)` 得到高分辨率的 `num_out_ch` 通道输出。

  - 换句话说：

    ```text
    输入特征（embed_dim 通道） 
      → [1 个卷积: embed_dim → (num_out_ch*scale^2) ] 
      → PixelShuffle(scale) 
      → 输出 HR (num_out_ch 通道)
    ```

  1. 由于只用一个卷积层完成子像素映射，省去了“先映射到 num_feat 再映射到 num_feat*scale^2”所需的那一层卷积，参数更少、计算更省。

- **为什么叫“轻量化”**

  - 原本的经典 `pixelshuffle` 分支，需要至少两次卷积：
    1. `Conv(embed_dim → num_feat)`
    2. `Conv(num_feat → num_feat * scale^2)`
    3. 最后 `Conv(num_feat → num_out_ch)`
        —— 合计 3 层卷积。
  - 而 `pixelshuffledirect` 只需：
    1. `Conv(embed_dim → num_out_ch * scale^2)`
    2. `PixelShuffle(scale)`
        —— 合计 1 层卷积。
  - 这样做的参数量和算力开销显著减少，但也可能损失部分特征表达能力，需要在轻量化与精度之间权衡。

- **`patches_resolution` 参数**

  - `UpsampleOneStep` 接受 `(patches_resolution[0], patches_resolution[1])` 作为额外信息，一般是告诉模块“输入特征图在解码前经过了怎样的分块或降采样”，以便正确调整子像素重排时的张量形状。

  - 具体实现里，你会看到：

    ```python
    self.conv = nn.Conv2d(
       in_channels=embed_dim,
       out_channels=num_out_ch * (upscale**2),
       kernel_size=3, 
       stride=1, 
       padding=1
    )
    ```

    然后在 `forward` 里做 `feature = self.conv(x)`，紧接着 `pixel_shuffle(feature, upscale)` 返回 `(H * upscale, W * upscale)`。

------

## 3. nearest+conv（真实场景 SR 方案）

```python
elif self.upsampler == 'nearest+conv':
    # for real-world SR (less artifacts)
    assert self.upscale == 4, 'only support x4 now.'
    self.conv_before_upsample = nn.Sequential(
        nn.Conv2d(embed_dim, num_feat, 3, 1, 1),
        nn.LeakyReLU(inplace=True)
    )
    # 下面几层都是不含像素重排的普通卷积
    self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
    self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
    self.conv_hr  = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
    self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)
    self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)
```

### 核心思路

- **“最近邻插值 + 卷积””的混合策略**

  - 在真实场景下（Noisy / JPEG 压缩 / 含模拟降采样的图像），直接使用子像素卷积（PixelShuffle）可能会导致伪影 (checkerboard artifacts)。
  - “Nearest + Conv” 方案就是先用最简单的最近邻插值（`nn.Upsample(scale_factor=2, mode='nearest')`）把特征图逐步拉升，然后再用普通卷积来细化纹理。
  - 由于 nearest 插值不会引入可学习参数，也不会出现 checkerboard 问题；后续用 3×3 卷积去细化、去噪，使得结果更平滑、更真实。

- **代码拆解（及可能的 Forward 流程）**

  1. `conv_before_upsample = Conv(embed_dim → num_feat) + LeakyReLU`

     - 同样是把 backbone 输出的 `embed_dim` 通道特征先映射到 `num_feat`。

  2. **第一次最近邻插值 + conv_up1**

     ```python
     x = self.conv_before_upsample(x)            # (B, num_feat, H, W)
     x = nn.functional.interpolate(x, scale_factor=2, mode='nearest')
     x = self.lrelu(self.conv_up1(x))           # (B, num_feat, H*2, W*2)
     ```

  3. **第二次最近邻插值 + conv_up2**

     ```python
     x = nn.functional.interpolate(x, scale_factor=2, mode='nearest')
     x = self.lrelu(self.conv_up2(x))           # (B, num_feat, H*4, W*4)
     ```

     - 因为 `assert self.upscale == 4`，所以典型做两次 x2 最近邻插值，相当于一次性 x4。

  4. **高分辨率特征细化**

     ```python
     x = self.lrelu(self.conv_hr(x))            # (B, num_feat, H*4, W*4)
     x = self.conv_last(x)                      # (B, num_out_ch, H*4, W*4)
     ```

     - 先经过 `conv_hr`（保持通道数），进一步增强细节；再用 `conv_last` 映射到 `num_out_ch`（通常是 3）输出重建结果。

### 优点与适用场景

- **优点**
  - 最近邻插值（nearest）非常高效，区别于双线性等插值，不会引入模糊或 checkerboard 伪影。
  - 卷积层负责补充插值后缺失的纹理细节，对噪声、压缩伪影等有更强的鲁棒性。
  - 在真实拍摄场景、手机拍摄降采样、JPEG 高压缩等情况下，往往能获得更自然真实的细节。
- **缺点/局限**
  - 相比 PixelShuffle，总的参数量可能更大（连续多次卷积）。
  - 插值层本身不会改变通道数，每次插值后都要紧跟一次卷积，计算复杂度也会相应增加。
  - 只能支持固定的放大倍数（这里写死 `upscale==4`），通用性较差。

------

## 4. else 分支：纯卷积重建（去噪/去压缩伪影场景）

```python
else:
    # for image denoising and JPEG compression artifact reduction
    self.conv_last1 = nn.Conv2d(embed_dim, embed_dim_temp, 3, 1, 1)
    self.conv_last2 = nn.Conv2d(embed_dim_temp, int(embed_dim_temp/2), 3, 1, 1)
    self.conv_last3 = nn.Conv2d(int(embed_dim_temp/2), num_out_ch, 3, 1, 1)
```

### 核心思路

- **不做空间维度上的“放大”**

  - 这一分支下没有插值或子像素操作，因此输出与输入大小相同。它更适合在“保持原图分辨率”前提下，去除噪声、压缩伪影、JPEG 重建等任务。
  - 三层纯卷积按顺序把 `embed_dim` → `embed_dim_temp` → `embed_dim_temp/2` → `num_out_ch`，逐步提取特征并映射回最终的通道数（一般也是 3 通道）。

- **代码拆解**

  1. `conv_last1 = Conv(embed_dim → embed_dim_temp)`
  2. `conv_last2 = Conv(embed_dim_temp → embed_dim_temp/2)`
  3. `conv_last3 = Conv(embed_dim_temp/2 → num_out_ch)`

  - 典型 Forward：

    ```python
    x = self.conv_last1(x)
    x = F.leaky_relu(x, 0.2, inplace=True)   # 通常会加激活
    x = self.conv_last2(x)
    x = F.leaky_relu(x, 0.2, inplace=True)
    x = self.conv_last3(x)
    ```

  - 最终输出的 H×W 与输入一致，只是在通道上经过几层映射，从而让网络专注于**“修复”**、**“去噪”** 或 **“去伪影”**，没有放大操作。

### 优点与适用场景

- **优点**
  - 结构最简单，专注于“低分辨率”图像增强/去噪/JPEG 伪影去除，参数量小，推理速度快。
  - 不需要插值或子像素，仅用连续卷积就可完成重建，所以不存在上采样伪影问题。
- **缺点/局限**
  - 只能在同一分辨率下对图像做“恢复”，无法获得更高分辨率。
  - 主要适用于去噪、去压缩伪影等任务，不具备超分（SR）功能。

------

## 四种重建方式的对比总结

| 方案                   | 上采样方式                          | 特征通道映射                                                 | 适用场景                      | 优缺点简述                                                   |
| ---------------------- | ----------------------------------- | ------------------------------------------------------------ | ----------------------------- | ------------------------------------------------------------ |
| **pixelshuffle**       | 子像素卷积（PixelShuffle）          | `embed_dim → num_feat → num_feat*scale² → ↓num_out_ch`       | 经典/Synthetic SR             | + 子像素直观、重建效果好– 参数多、显存开销大，易出现伪影     |
| **pixelshuffledirect** | 一次性子像素卷积（轻量级）          | `embed_dim → num_out_ch*scale² → PixelShuffle`               | 轻量级 SR （移动端/参数受限） | + 只用 1 层卷积，参数少、速度快– 可能精度不如 multi-stage 子像素方案 |
| **nearest+conv**       | 最近邻插值（×2 → ×2）+ 多层卷积细化 | `embed_dim → num_feat → interpol ×2 → conv_up1 → ×2 → conv_up2 → conv_hr → num_out_ch` | 真实场景 SR（噪声/压缩伪影）  | + 抑制 checkerboard，鲁棒性好– 参数和计算量一般高于子像素方案，且仅支持固定位 4 倍上采样 |
| **else(纯 conv)**      | 无（保持原分辨率）                  | `embed_dim → embed_dim_temp → embed_dim_temp/2 → num_out_ch` | 去噪、JPEG 伪影修复、图像增强 | + 模型最简单，速度快，专注同分辨率下修复– 不具备放大功能，只能做同分辨率的重建/修复 |

------

### 何时选用哪种方案？

1. **纯粹研究合成数据上的高质量超分** → **pixelshuffle**（或者其他子像素多阶段卷积）。
2. **对推理速度/模型大小要求极限**（移动端、嵌入式）→ **pixelshuffledirect**（单层子像素卷积）。
3. **真实拍摄、JPEG 压缩、带噪声场景** → **nearest+conv**，因为 nearest 插值 + 卷积细化能更好地抑制伪影。
4. **非超分、只需同分辨率去噪/去伪影** → **纯卷积重建（else 分支）**，无需放大。

------

## 小结

- `pixelshuffle`（经典子像素方案）和 `pixelshuffledirect`（轻量版子像素方案）都属于通过 **“通道重排（PixelShuffle）”** 实现的上采样，前者分两步映射通道，中间有一层隐藏通道；后者一步映射直出，参数更少。
- `nearest+conv` 则先用 “插值 + 普通卷积” 的方式实现放大与细化，能抑制子像素卷积常见的 checkerboard 伪影，更适合真实场景下的超分需求。
- `else` 分支仅由连续卷积构成，用于同分辨率下的 **“图像重建/去噪/去压缩伪影”**，不涉及任何放大操作。

根据你的任务目标（是否需要放大？是否在真实噪声/压缩场景？是否对模型参数量有限制？）来选择相应的分支即可。这样就能清晰地理解这几种“模型重建方式”的设计初衷与适用场景。